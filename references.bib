@article{Akam2022,
  title = {Open-Source, {{Python-based}}, Hardware and Software for Controlling Behavioural Neuroscience Experiments},
  author = {Akam, Thomas and Lustig, Andy and Rowland, James M and Kapanaiah, Sampath KT and {Esteve-Agraz}, Joan and Panniello, Mariangela and M{\'a}rquez, Cristina and Kohl, Michael M and K{\"a}tzel, Dennis and Costa, Rui M and Walton, Mark E},
  editor = {Kemere, Caleb and Wassum, Kate M and Kemere, Caleb and Siegle, Josh},
  year = 2022,
  month = jan,
  journal = {eLife},
  volume = {11},
  pages = {e67846},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.67846},
  urldate = {2025-11-16},
  abstract = {Laboratory behavioural tasks are an essential research tool. As questions asked of behaviour and brain activity become more sophisticated, the ability to specify and run richly structured tasks becomes more important. An increasing focus on reproducibility also necessitates accurate communication of task logic to other researchers. To these ends, we developed pyControl, a system of open-source hardware and software for controlling behavioural experiments comprising a simple yet flexible Python-based syntax for specifying tasks as extended state machines, hardware modules for building behavioural setups, and a graphical user interface designed for efficiently running high-throughput experiments on many setups in parallel, all with extensive online documentation. These tools make it quicker, easier, and cheaper to implement rich behavioural tasks at scale. As important, pyControl facilitates communication and reproducibility of behavioural experiments through a highly readable task definition syntax and self-documenting features. Here, we outline the system's design and rationale, present validation experiments characterising system performance, and demonstrate example applications in freely moving and head-fixed mouse behaviour.},
  keywords = {Behaviour,Hardware,open source,Software},
  file = {/Users/roaldarbol/Zotero/storage/2II7HB6Q/Akam et al._2022_Open-source, Python-based, hardware and software for controlling behavioural neuroscience experiment.pdf}
}

@article{Chagas2017a,
  title = {The \texteuro 100 Lab: {{A 3D-printable}} Open-Source Platform for Fluorescence Microscopy, Optogenetics, and Accurate Temperature Control during Behaviour of Zebrafish, {{Drosophila}}, and {{Caenorhabditis}} Elegans},
  shorttitle = {The \texteuro 100 Lab},
  author = {Chagas, Andre Maia and {Prieto-Godino}, Lucia L. and Arrenberg, Aristides B. and Baden, Tom},
  year = 2017,
  month = jul,
  journal = {PLOS Biology},
  volume = {15},
  number = {7},
  pages = {e2002702},
  publisher = {Public Library of Science},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.2002702},
  urldate = {2025-11-16},
  abstract = {Small, genetically tractable species such as larval zebrafish, Drosophila, or Caenorhabditis elegans have become key model organisms in modern neuroscience. In addition to their low maintenance costs and easy sharing of strains across labs, one key appeal is the possibility to monitor single or groups of animals in a behavioural arena while controlling the activity of select neurons using optogenetic or thermogenetic tools. However, the purchase of a commercial solution for these types of experiments, including an appropriate camera system as well as a controlled behavioural arena, can be costly. Here, we present a low-cost and modular open-source alternative called `FlyPi'. Our design is based on a 3D-printed mainframe, a Raspberry Pi computer, and high-definition camera system as well as Arduino-based optical and thermal control circuits. Depending on the configuration, FlyPi can be assembled for well under \texteuro 100 and features optional modules for light-emitting diode (LED)-based fluorescence microscopy and optogenetic stimulation as well as a Peltier-based temperature stimulator for thermogenetics. The complete version with all modules costs approximately \texteuro 200 or substantially less if the user is prepared to `shop around'. All functions of FlyPi can be controlled through a custom-written graphical user interface. To demonstrate FlyPi's capabilities, we present its use in a series of state-of-the-art neurogenetics experiments. In addition, we demonstrate FlyPi's utility as a medical diagnostic tool as well as a teaching aid at Neurogenetics courses held at several African universities. Taken together, the low cost and modular nature as well as fully open design of FlyPi make it a highly versatile tool in a range of applications, including the classroom, diagnostic centres, and research labs.},
  langid = {english},
  keywords = {3D printing,Cameras,Drosophila melanogaster,Fluorescence imaging,Larvae,Light emitting diodes,Optogenetics,Zebrafish},
  file = {/Users/roaldarbol/Zotero/storage/6G78IHS2/Chagas et al._2017_The €100 lab A 3D-printable open-source platform for fluorescence microscopy, optogenetics, and acc.pdf}
}

@article{Chen2017b,
  title = {{{ArControl}}: {{An Arduino-Based Comprehensive Behavioral Platform}} with {{Real-Time Performance}}},
  shorttitle = {{{ArControl}}},
  author = {Chen, Xinfeng and Li, Haohong},
  year = 2017,
  month = dec,
  journal = {Frontiers in Behavioral Neuroscience},
  volume = {11},
  publisher = {Frontiers},
  issn = {1662-5153},
  doi = {10.3389/fnbeh.2017.00244},
  urldate = {2025-11-16},
  abstract = {Studying animal behavior in the lab requires reliable delivering stimulations and monitoring responses. We constructed a comprehensive behavioral platform (ArControl: Arduino Control Platform) that was an affordable, easy-to-use, high-performance solution combined software and hardware components. The hardware component was consisted of an Arduino UNO board and a simple drive circuit. As for software, the ArControl provided a stand-alone and intuitive GUI (graphical user interface) application that did not require users to master scripts. The experiment data were automatically recorded with the built in DAQ (data acquisition) function. The ArControl also allowed the behavioral schedule to be entirely stored in and operated on the Arduino chip. This made the ArControl a genuine, real-time system with high temporal resolution ({$<$}1ms). We tested the ArControl, based on strict performance measurements and two mice behavioral experiments. The results showed that the ArControl was an adaptive and reliable system suitable for behavioral research.},
  langid = {english},
  keywords = {arduino,Behavioral platform,go/no-go,methods,Real-time system,Software,State Notation},
  file = {/Users/roaldarbol/Zotero/storage/ZURZ3G3X/Chen and Li_2017_ArControl An Arduino-Based Comprehensive Behavioral Platform with Real-Time Performance.pdf}
}

@article{Kane2020a,
  title = {Real-Time, Low-Latency Closed-Loop Feedback Using Markerless Posture Tracking},
  author = {Kane, Gary A and Lopes, Gon{\c c}alo and Saunders, Jonny L and Mathis, Alexander and Mathis, Mackenzie W},
  editor = {Berman, Gordon J and Behrens, Timothy E and Berman, Gordon J and Branco, Tiago},
  year = 2020,
  month = dec,
  journal = {eLife},
  volume = {9},
  pages = {e61909},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.61909},
  urldate = {2022-02-21},
  abstract = {The ability to control a behavioral task or stimulate neural activity based on animal behavior in real-time is an important tool for experimental neuroscientists. Ideally, such tools are noninvasive, low-latency, and provide interfaces to trigger external hardware based on posture. Recent advances in pose estimation with deep learning allows researchers to train deep neural networks to accurately quantify a wide variety of animal behaviors. Here, we provide a new DeepLabCut-Live! package that achieves low-latency real-time pose estimation (within 15 ms, {$>$}100 FPS), with an additional forward-prediction module that achieves zero-latency feedback, and a dynamic-cropping mode that allows for higher inference speeds. We also provide three options for using this tool with ease: (1) a stand-alone GUI (called DLC-Live! GUI), and integration into (2) Bonsai, and (3) AutoPilot. Lastly, we benchmarked performance on a wide range of systems so that experimentalists can easily decide what hardware is required for their needs.},
  keywords = {any animal,DeepLabCut,low-latency,pose-estimation,real-time tracking},
  file = {/Users/roaldarbol/Zotero/storage/VN3UFVCX/Kane et al._2020_Real-time, low-latency closed-loop feedback using markerless posture tracking.pdf}
}

@incollection{Kluyver2016,
  title = {Jupyter {{Notebooks}} -- a Publishing Format for Reproducible Computational Workflows},
  booktitle = {Positioning and {{Power}} in {{Academic Publishing}}: {{Players}}, {{Agents}} and {{Agendas}}},
  author = {Kluyver, Thomas and {Ragan-Kelley}, Benjamin and P\&\#233 and Rez, Fernando and Granger, Brian and Bussonnier, Matthias and Frederic, Jonathan and Kelley, Kyle and Hamrick, Jessica and Grout, Jason and Corlay, Sylvain and Ivanov, Paul and Avila, Dami\&\#225 and {n} and Abdalla, Safia and Willing, Carol and Team, Jupyter Development},
  year = 2016,
  pages = {87--90},
  publisher = {IOS Press},
  doi = {10.3233/978-1-61499-649-1-87},
  urldate = {2025-12-15},
  langid = {english},
  file = {/Users/roaldarbol/Zotero/storage/FY2RZ7BJ/978-1-61499-649-1-87.html}
}

@article{Lopes2015,
  title = {Bonsai: {{An}} Event-Based Framework for Processing and Controlling Data Streams},
  author = {Lopes, Gon{\c c}alo and Bonacchi, Niccol{\`o} and Fraz{\~a}o, Jo{\~a}o and Neto, Joana P. and Atallah, Bassam V. and Soares, Sofia and Moreira, Lu{\'i}s and Matias, Sara and Itskov, Pavel M. and Correia, Patr{\'i}cia A. and Medina, Roberto E. and Calcaterra, Lorenza and Dreosti, Elena and Paton, Joseph J. and Kampff, Adam R.},
  year = 2015,
  journal = {Frontiers in Neuroinformatics},
  volume = {9},
  number = {APR},
  pages = {1--14},
  issn = {16625196},
  doi = {10.3389/fninf.2015.00007},
  abstract = {The design of modern scientific experiments requires the control and monitoring of many different data streams. However, the serial execution of programming instructions in a computer makes it a challenge to develop software that can deal with the asynchronous, parallel nature of scientific data. Here we present Bonsai, a modular, high-performance, open-source visual programming framework for the acquisition and online processing of data streams. We describe Bonsai's core principles and architecture and demonstrate how it allows for the rapid and flexible prototyping of integrated experimental designs in neuroscience. We specifically highlight some applications that require the combination of many different hardware and software components, including video tracking of behavior, electrophysiology and closed-loop control of stimulation.},
  keywords = {Behavior control,Data acquisition system,Data stream processing,Electrophysiology,Open-source,Parallel processing,Rapid prototyping,Video tracking},
  file = {/Users/roaldarbol/Zotero/storage/VQVFVM4T/Lopes et al._2015_Bonsai An event-based framework for processing and controlling data streams.pdf}
}

@article{Lopes2021,
  title = {Creating and Controlling Visual Environments Using {{BonVision}}},
  author = {Lopes, Gon{\c c}alo and Farrell, Karolina and Horrocks, Edward AB and Lee, Chi-Yu and Morimoto, Mai M and Muzzu, Tomaso and Papanikolaou, Amalia and Rodrigues, Fabio R and Wheatcroft, Thomas and Zucca, Stefano and Solomon, Samuel G and Saleem, Aman B},
  editor = {Baker, Chris I and Newman, Jonathan P and Maia Chagas, Andr{\'e} and Koay, Sue Ann},
  year = 2021,
  month = apr,
  journal = {eLife},
  volume = {10},
  pages = {e65541},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.65541},
  urldate = {2025-11-16},
  abstract = {Real-time rendering of closed-loop visual environments is important for next-generation understanding of brain function and behaviour, but is often prohibitively difficult for non-experts to implement and is limited to few laboratories worldwide. We developed BonVision as an easy-to-use open-source software for the display of virtual or augmented reality, as well as standard visual stimuli. BonVision has been tested on humans and mice, and is capable of supporting new experimental designs in other animal models of vision. As the architecture is based on the open-source Bonsai graphical programming language, BonVision benefits from native integration with experimental hardware. BonVision therefore enables easy implementation of closed-loop experiments, including real-time interaction with deep neural networks, and communication with behavioural and physiological measurement and manipulation devices.},
  keywords = {augmented reality,navigation,spatial vision,virtual reality},
  file = {/Users/roaldarbol/Zotero/storage/5UFBHEH4/Lopes et al._2021_Creating and controlling visual environments using BonVision.pdf}
}

@misc{Maning2023,
  title = {What's the {{Best Language}} for {{Microcontrollers}}: {{MicroPython}}, {{CircuitPython}}, {{Arduino}}, or {{C}}?},
  shorttitle = {What's the {{Best Language}} for {{Microcontrollers}}},
  author = {Maning, Jayric},
  year = 2023,
  month = may,
  journal = {MUO},
  urldate = {2025-11-16},
  abstract = {Which programming language should you use for your microcontroller projects? Let's explore the four best options.},
  chapter = {DIY},
  howpublished = {https://www.makeuseof.com/microcontroller-best-language-micropython-circuitpython-arduino-c/},
  langid = {english},
  file = {/Users/roaldarbol/Zotero/storage/Q6XKFSW6/microcontroller-best-language-micropython-circuitpython-arduino-c.html}
}

@article{Mathis2018,
  title = {{{DeepLabCut}}: Markerless Pose Estimation of User-Defined Body Parts with Deep Learning},
  shorttitle = {{{DeepLabCut}}},
  author = {Mathis, Alexander and Mamidanna, Pranav and Cury, Kevin M. and Abe, Taiga and Murthy, Venkatesh N. and Mathis, Mackenzie Weygandt and Bethge, Matthias},
  year = 2018,
  month = sep,
  journal = {Nature Neuroscience},
  volume = {21},
  number = {9},
  pages = {1281--1289},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-018-0209-y},
  urldate = {2021-06-27},
  abstract = {Quantifying behavior is crucial for many applications in neuroscience. Videography provides easy methods for the observation and recording of animal behavior in diverse settings, yet extracting particular aspects of a behavior for further analysis can be highly time consuming. In motor control studies, humans or other animals are often marked with reflective markers to assist with computer-based tracking, but markers are intrusive, and the number and location of the markers must be determined a priori. Here we present an efficient method for markerless pose estimation based on transfer learning with deep neural networks that achieves excellent results with minimal training data. We demonstrate the versatility of this framework by tracking various body parts in multiple species across a broad collection of behaviors. Remarkably, even when only a small number of frames are labeled (\textasciitilde 200), the algorithm achieves excellent tracking performance on test frames that is comparable to human accuracy.},
  copyright = {2018 The Author(s)},
  langid = {english},
  annotation = {Bandiera\_abtest: a\\
Cg\_type: Nature Research Journals\\
Primary\_atype: Research\\
Subject\_term: Behavioural methods;Computational neuroscience;Machine learning\\
Subject\_term\_id: behavioural-methods;computational-neuroscience;machine-learning},
  file = {/Users/roaldarbol/Zotero/storage/Q5ZGKQI6/Mathis et al. - 2018 - DeepLabCut markerless pose estimation of user-def.pdf;/Users/roaldarbol/Zotero/storage/I598XNML/s41593-018-0209-y.html}
}

@article{Muller2015a,
  title = {Python in Neuroscience},
  author = {Muller, Eilif and Bednar, James A. and Diesmann, Markus and Gewaltig, Marc-Oliver and Hines, Michael and Davison, Andrew P.},
  year = 2015,
  month = apr,
  journal = {Frontiers in Neuroinformatics},
  volume = {9},
  publisher = {Frontiers},
  issn = {1662-5196},
  doi = {10.3389/fninf.2015.00011},
  urldate = {2025-11-16},
  abstract = {This Research Topic of Frontiers in Neuroinformatics is dedicated to the memory of Rolf K\&\#246;tter (1961--2010), who was the Frontiers Associate Editor responsible for this Research Topic, and who gave us considerable support and encouragement during the process of conceiving and launching the Topic, and throughout the reviewing process.Computation is becoming essential across all sciences, for data acquisition and analysis, automation, and hypothesis testing via modeling and simulation. As a consequence, software development is becoming a critical scientific activity. Training of scientists in programming, software development, and computational thinking (Wilson, 2006), choice of tools, community-building and interoperability are all issues that should be addressed, if we wish to accelerate scientific progress while maintaining standards of correctness and reproducibility.The Python programming language in particular has seen a surge in popularity across the sciences, for reasons which include its readability, modularity, and large standard library (also see Figure 1). The use of Python as a scientific programming language began to increase with the development of numerical libraries for optimized operations on large arrays in the late 1990s, in which an important development was the merging of the competing Numeric and Numarray packages in 2006 to form NumPy (Oliphant, 2007). As Python and NumPy have gained traction in a given scientific domain, we have seen the emergence of domain-specific ecosystems of open-source Python software developed by scientists. It became clear to us in 2007 that we were on the cusp of an emerging Python in neuroscience ecosystem, particularly in computational neuroscience and neuroimaging, but also in electrophysiological data analysis and in psychophysics. Two major strengths of Python are its modularity and ability to easily ``glue'' together different programming languages, which together facilitate the interaction of modular components and their composition into larger systems. This focus on reusable components, which has proven its value in commercial and open-source software development (Brooks, 1987), is, we contend, essential for scientific computing in neuroscience, if we are to cope with the increasingly large amounts of data being produced in experimental labs, and if we wish to understand and model the brain in all its complexity, We therefore felt that it was timely and important to raise awareness of the emerging Python in Neuroscience software ecosystem amongst researchers developing Python-based tools, but also in the larger neuroscience community. Our goals were several-fold:- establish a critical mass for Python use and development in the eyes of the community;- encourage interoperability and collaboration between developers;- expose neuroscientists to the new Python-based tools now available.From this was born the idea for a Research Topic in Frontiers in Neuroinformatics on ``Python in Neuroscience'' to showcase those projects we were aware of, and to give exposure to projects of which we were not aware. Although it may seem strange at first glance to centre a Research Topic around a tool, rather than around a scientific problem, we feel it is justified by the increasingly critical role of scientific programming in neuroscience research, and by the particular strengths of the Python language and the broader Python scientific computing ecosystem.Collected in this Research Topic are 24 articles describing some ways in which neuroscience researchers around the world are turning to the Python programming language to get their job done faster and more efficiently.[Figure 1 around here]Figure 1. Beginning to use Python for scientific computing can be a liberating, even exhilarating experience. Comic by Randall Munroe, available from http://xkcd.com/353/. Reproduced under the terms of the Creative Commons Attribution-NonCommercial 2.5 License (see http://xkcd.com/license.html)Overview of the Research TopicWe will now briefly summarize the 24 articles in the Research Topic, drawing out common themes.Both Southey et al. (2008) and Yanashima et al. (2009) use Python for bioinformatics applications, but in very different areas. Yanashima et al. have developed a Python package for graph-theoretical analysis of biomolecular networks, BioNetpy, and employed it to investigate protein networks associated with Alzheimer's disease. Southey et al.'s study demonstrates the wide breadth of application of Python, and the large number of high quality scientific libraries available, combining existing tools for bioinformatics, machine learning and web development to build an integrated pipeline for identification of prohormone precursors and prediction of prohormone cleavage sites.Jurica and van Leeuwen (2009) address the needs of scientists who already have significant amounts of code written in MATLAB\&\#174; and who wish to transfer this to Python. They present OMPC, which uses syntax adaptation and emulation to allow transparent import of existing MATLAB\&\#174; functions into Python programs. Three articles reported on new tools in the domain of neuroimaging. Hanke et al. (2009) report on PyMVPA, a Python framework for machine learning-based data analysis, and its application to analysis of fMRI, EEG, MEG, and extracellular electrophysiology recordings. Gouws et al. (2009) describe DataViewer3D, a Python application for displaying and integrating data from multiple neuroimaging modalities, showcasing Python's abilities to easily interface with libraries written in other languages, such as C++, and to integrate them into user-friendly systems. Strangman et al. (2009) emphasize the advantages of Python for ``swift prototyping followed by efficient transition to stable production systems'' in their description of NinPy, a toolkit for near-infrared neuroimaging.Zito et al. (2009) and Ince et al. (2009) both report on the use of Python for general purpose data analysis, with a focus on machine learning and information theory respectively. Zito et al. have developed MDP, the Modular toolkit for Data Processing, a collection of computationally efficient data analysis modules that can be combined into complex pipelines. MDP was originally developed for theoretical research in neuroscience, but has broad application in general scientific data analysis and in teaching. Ince et al. (2009) describe the use of Python for information-theoretic analysis of neuroscience data, outlining algorithmic, statistical and numerical challenges in the application of information theory in neuroscience, and explaining how the use of Python has significantly improved the speed and domain of applicability of the algorithms, allowing more ambitious analyses of more complex data sets. Their code is available as an open-source package, pyEntropy.Three articles report on tools for visual stimulus generation, for use in visual neurophysiology and psychophysics experiments. Straw (2008) describes VisionEgg, while Peirce (2009) presents PsychoPy, both of which are easy-to-use and easy-to-install applications that make use of OpenGL to generate temporally and spatially precise, arbitrarily complex visual stimulation protocols. Python is used to provide a simple, intuitive interface to the underlying graphics libraries, to provide a graphical user interface, and to interface with external hardware. PsychoPy can also generate and deliver auditory stimuli. Spacek et al. (2009) also report on a Python library for visual stimulus generation, as part of a toolkit for the acquisition and analysis of highly parallel electrophysiological recordings from cat and rat visual cortex. The other two components in the toolkit are for electrophysiological waveform visualization and spike sorting; and for spike train and stimulus analysis. The authors note ``The requirements and solutions for these projects differed greatly, yet we found Python to be well suited for all three.'' Also in the domain of electrophysiology, Garcia and Fourcaud-Trocm\&\#233; (2009) describe OpenElectrophy, an application for efficient storage and analysis of large electrophysiology datasets, which includes a graphical user interface for interactive visualization and exploration and a library of analysis routines, including several spike-sorting methods.By far the largest contribution to the Research Topic came from the field of modelling and simulation, with 12 articles on the topic. Nine of these articles present neuroscience simulation environments with Python scripting interfaces. In most cases, the Python interface was added to an existing simulator written in a compiled language such as C++. This was the case for NEURON (Hines et al., 2009), NEST (Eppler et al., 2009), PCSIM (Pecevski et al., 2009), Nengo (Stewart et al., 2009), MOOSE (Ray and Bhalla, 2008), STEPS (Wils and De Schutter, 2009) and NCS (Drewes et al., 2009). However, as the articles by Goodman and Brette (2008) on the Brian simulator and Bednar (2009) on the Topographica simulator demonstrate, it is also possible to develop new simulation environments purely in Python, making use of the vectorization techniques available in the underlying NumPy package to obtain computational efficiency. The range of modelling domains of these simulators is wide, from stochastic simulation of coupled reaction-diffusion systems (STEPS), through simulation of morphologically detailed neurons and networks (NEURON, MOOSE), highly-efficient large-scale networks of spiking point neurons (NEST, PCSIM, NCS, Brian) to population coding or point-neuron models of large brain regions (Nengo, Topographica). Note that although we have categorized each simulator by its main area of application, most of these tools support modelling at a range of scales and levels of detail: Bednar (2009), for example, describes the integration of a spiking NEST simulation as one component in a Topographica simulation.The addition of Python interfaces to such a large number of widely used simulation environments suggested a huge opportunity to enhance interoperability between different simulators, making use of the common scripting language, which in turn has the potential to enhance the transfer of technology, knowledge and models between users of the different simulators, and to promote model reuse. Davison et al. (2009) describe PyNN, a common Python interface to multiple simulators, which enables the same modelling and simulation script to be run on any supported simulator without modification. At the time of writing, PyNN supports NEURON, NEST, PCSIM and Brian, with MOOSE support under development. The existence of such a common ``meta-simulator'' then makes it much easier for scientists developing new, hardware-based approaches to neural simulation to engage with the computational neuroscience community, as evidenced by the article by Br\&\#252;derle et al. (2009) on interfacing a novel neuromorphic hardware system with PyNN.Finally, Fox et al. (2009) describe the possibilities when one is not limited to a single simulator, but can use Python to integrate multiple models into a brain-wide system. In their development of an integrated basal ganglia-hippocampal formation model for spatial navigation and its embodiment in a simulated robotic environment, Fox et al. found that Python offers ``a significant reduction in development time, without a corresponding significant increase in execution time''.It is important to note that most or all of the Python tools and libraries described in the Research Topic are open source and hence free to download, use and extend.DiscussionThis editorial is being written six years after the first articles in the Research Topic were published. It is with the benefit of considerable hindsight, therefore, that we can confidently say that our goals in launching this Research Topic -- to establish a critical mass for Python use and development in the eyes of the community and to encourage interoperability and collaboration between developers -- have been met or exceeded.The average number of citations per article for the Research Topic as a whole is 54, or approximately 9 per year, using figures from Google Scholar. Although citation counts from Google Scholar tend to be higher than those from Journal Citation Reports so the numbers are not directly comparable, this compares favourably with the impact factors of well respected journals such as Journal of Neuroscience or PLoS Computational Biology. Some of the articles were much more highly cited, with three of them being cited more than 20 times per year, on average, over the period. Four of the articles were chosen to ``climb the tier'' in the Frontiers system, and were followed up by Focused Review articles in Frontiers in Neuroscience (Davison, Hines and Muller, 2009; Goodman and Brette, 2009; Hanke et al., 2010; Ince et al., 2010), another was the subject of a commentary (Einevoll, 2009). Concerning the goals of interoperability and collaboration, several articles in a follow-up volume Python in Neuroscience II attest to the degree to which the developers of different tools have worked together, and prioritized interoperability in recent years. For example, the developers of OpenElectrophy (Garcia and Fourcaud-Trocm\&\#233;, 2009) and the community around PyNN (Davison et al., 2009) formed the nucleus of an effort to develop a baseline Python representation for electrophysiology data, which resulted in the Neo project, reported in the Python in Neuroscience II Research Topic (Garcia et al., 2014) together with two of the several projects which build on Neo (Pr\&\#246;pper and Obermayer, 2013; Sobolev et al., 2014). A new workflow system for computational neuroscience, Mozaik (Antol\&\#237;k and Davison, 2014) builds on both PyNN and Topographica (Bednar, 2009). PyNEST (Eppler et al., 2009) and PyNN developers collaborated with the INCF to improve the interoperability between these tools (Djurfeldt et al., 2014) when using the Connection Set Algebra (Djurfeldt, 2010). Finally, a number of tools have been built on the Python interface to NEURON (Hines et al., 2009), including morphforge (Hull and Willshaw, 2014) and LFPy (Lind\&\#233;n et al., 2014).Observing the rapid growth in adoption of Python in neuroscience over the last six years, which appears to continue to accelerate, it is clear that Python is here to stay, which augurs well for the growth, productivity, and rigour of computational methods in neuroscience.},
  langid = {english},
  keywords = {collaboration,interoperability,python language,scientific computing,Software Development},
  file = {/Users/roaldarbol/Zotero/storage/6Y9ZDCBY/Muller et al._2015_Python in neuroscience.pdf}
}

@article{Oellermann2022a,
  title = {Open {{Hardware}} in {{Science}}: {{The Benefits}} of {{Open Electronics}}},
  shorttitle = {Open {{Hardware}} in {{Science}}},
  author = {Oellermann, Michael and Jolles, Jolle W and Ortiz, Diego and Seabra, Rui and Wenzel, Tobias and Wilson, Hannah and Tanner, Richelle L},
  year = 2022,
  month = oct,
  journal = {Integrative and Comparative Biology},
  volume = {62},
  number = {4},
  pages = {1061--1075},
  issn = {1540-7063},
  doi = {10.1093/icb/icac043},
  urldate = {2025-11-16},
  abstract = {Openly shared low-cost electronic hardware applications, known as open electronics, have sparked a new open-source movement, with much untapped potential to advance scientific research. Initially designed to appeal to electronic hobbyists, open electronics have formed a global ``maker'' community and are increasingly used in science and industry. In this perspective article, we review the current costs and benefits of open electronics for use in scientific research ranging from the experimental to the theoretical sciences. We discuss how user-made electronic applications can help (I) individual researchers, by increasing the customization, efficiency, and scalability of experiments, while improving data quantity and quality; (II) scientific institutions, by improving access to customizable high-end technologies, sustainability, visibility, and interdisciplinary collaboration potential; and (III) the scientific community, by improving transparency and reproducibility, helping decouple research capacity from funding, increasing innovation, and improving collaboration potential among researchers and the public. We further discuss how current barriers like poor awareness, knowledge access, and time investments can be resolved by increased documentation and collaboration, and provide guidelines for academics to enter this emerging field. We highlight that open electronics are a promising and powerful tool to help scientific research to become more innovative and reproducible and offer a key practical solution to improve democratic access to science.},
  file = {/Users/roaldarbol/Zotero/storage/G2NIQNR2/Oellermann et al._2022_Open Hardware in Science The Benefits of Open Electronics.pdf;/Users/roaldarbol/Zotero/storage/LCGPQJ9P/icac043.html}
}

@article{Pearce2016,
  title = {Return on Investment for Open Source Scientific Hardware Development},
  author = {Pearce, J. M.},
  year = 2016,
  month = apr,
  journal = {Science and Public Policy},
  volume = {43},
  number = {2},
  pages = {192--195},
  issn = {0302-3427},
  doi = {10.1093/scipol/scv034},
  urldate = {2025-11-16},
  abstract = {The availability of free and open source hardware designs that can be replicated with low-cost 3D printers provides large values to scientists who need highly-customized low-volume production scientific equipment. Digital manufacturing technologies have only recently become widespread and the return on investment (ROI) was not clear, so funding for open hardware development was historically sparse. This paper clarifies a method for determining an ROI for the development of scientific free and open source hardware (FOSH). By using an open source hardware design that can be manufactured digitally, the relatively minor development costs result in enormous ROIs for the scientific community. A case study is presented of a syringe pump released under open license, which results in ROIs for funders ranging from hundreds to thousands of percent after only a few months. It is clear that policies encouraging FOSH scientific hardware development should be adopted by organizations interested in maximizing return on public investments for science.},
  file = {/Users/roaldarbol/Zotero/storage/S29W8Q9W/Pearce_2016_Return on investment for open source scientific hardware development.pdf;/Users/roaldarbol/Zotero/storage/67C5XPPB/scv034.html}
}

@article{Pearce2017,
  title = {Impacts of {{Open Source Hardware}} in {{Science}} and {{Engineering}}},
  author = {Pearce, Joshua},
  year = 2017,
  journal = {The Bridge},
  publisher = {National Academy of Sciences},
  urldate = {2025-11-16},
  abstract = {There is an opportunity to radically reduce the costs of experimental research while improving it by supporting the development of free and open source hardware (FOSH) for science and engineering. By harnessing a scalable open source method, federal funding is spent just once for the development of scientific equipment and then a return on this investment is realized by direct digital replication of scientific devices for only the costs of materials. FOSH for science and engineering has been growing at a rapid pace and already supports many fields. Scaled peer production and digital replica-tion reduce traditional costs by 90-99 percent, making scientific equipment much more accessible not only for research but also for preparation of the next generation of scientists and engineers as research-grade tools are available for science, technology, engineering, and math (STEM) education. I propose four straightforward and negative-net-cost policies to support FOSH development and improve access to scientific tools in the United States. The policies will directly save millions in research and STEM education expenditures, while providing researchers and students access to better equipment, which will promote advances in technology and concomitant benefits for the US economy. Free and open source hardware can reduce research and education costs, increase access, and enhance scientific and technological progress.},
  file = {/Users/roaldarbol/Zotero/storage/VHP99XSN/Pearce_2017_Impacts of Open Source Hardware in Science and Engineering.pdf}
}

@article{Pearce2020,
  title = {Economic Savings for Scientific Free and Open Source Technology: {{A}} Review},
  shorttitle = {Economic Savings for Scientific Free and Open Source Technology},
  author = {Pearce, Joshua M.},
  year = 2020,
  month = oct,
  journal = {HardwareX},
  volume = {8},
  pages = {e00139},
  issn = {2468-0672},
  doi = {10.1016/j.ohx.2020.e00139},
  urldate = {2025-11-16},
  abstract = {Both the free and open source software (FOSS) as well as the distributed digital manufacturing of free and open source hardware (FOSH) has shown particular promise among scientists for developing custom scientific tools. Early research found substantial economic savings for these technologies, but as the open source design paradigm has grown by orders of magnitude it is possible that the savings observed in the early work was isolated to special cases. Today there are examples of open source technology for science in the vast majority of disciplines and several resources dedicated specifically to publishing them. Do the tremendous economic savings observed earlier hold today? To answer that question, this study evaluates free and open source technologies in the two repositories compared to proprietary functionally-equivalent tools as a function of their use of Arduino-based electronics, RepRap-class 3-D printing, as well as the combination of the two. The results of the review find overwhelming evidence for a wide range of scientific tools, that open source technologies provide economic savings of 87\% compared to equivalent or lesser proprietary tools. These economic savings increased slightly to 89\% for those that used Arduino technology and even more to 92\% for those that used RepRap-class 3-D printing. Combining both Arduino and 3-D printing the savings averaged 94\% for free and open source tools over commercial equivalents. The results provide strong evidence for financial support of open source hardware and software development for the sciences. Given the overwhelming economic advantages of free and open source technologies, it appears financially responsible to divert funding of proprietary scientific tools and their development in favor of FOSH. Policies were outlined that provide nations with a template for strategically harvesting the opportunities provided by the free and open source paradigm.},
  keywords = {3-D printing,Custom designs,Customization,Distributed manufacturing,Economics,FOSH,FOSS,Free and open source,Free and open source software,Instrumentation,Libre hardware,Open design,Open hardware,Open innovation,Open science,Open science hardware,Open scientific hardware,Open source,Open source hardware,OScH,P2P,P2P manufacturing,RepRap,Science,Science finance,Science funding,Science policy,Scientific equipment,Scientific instruments},
  file = {/Users/roaldarbol/Zotero/storage/7M3PXTV7/Pearce_2020_Economic savings for scientific free and open source technology A review.pdf;/Users/roaldarbol/Zotero/storage/9G8W9JMA/S2468067220300481.html}
}

@article{Pereira2022,
  title = {{{SLEAP}}: {{A}} Deep Learning System for Multi-Animal Pose Tracking},
  shorttitle = {{{SLEAP}}},
  author = {Pereira, Talmo D. and Tabris, Nathaniel and Matsliah, Arie and Turner, David M. and Li, Junyu and Ravindranath, Shruthi and Papadoyannis, Eleni S. and Normand, Edna and Deutsch, David S. and Wang, Z. Yan and {McKenzie-Smith}, Grace C. and Mitelut, Catalin C. and Castro, Marielisa Diez and D'Uva, John and Kislin, Mikhail and Sanes, Dan H. and Kocher, Sarah D. and Wang, Samuel S.-H. and Falkner, Annegret L. and Shaevitz, Joshua W. and Murthy, Mala},
  year = 2022,
  month = apr,
  journal = {Nature Methods},
  volume = {19},
  number = {4},
  pages = {486--495},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/s41592-022-01426-1},
  urldate = {2025-02-06},
  abstract = {The desire to understand how the brain generates and patterns behavior has driven rapid methodological innovation in tools to quantify natural animal behavior. While advances in deep learning and computer vision have enabled markerless pose estimation in individual animals, extending these to multiple animals presents unique challenges for studies of social behaviors or animals in their natural environments. Here we present Social LEAP Estimates Animal Poses (SLEAP), a machine learning system for multi-animal pose tracking. This system enables versatile workflows for data labeling, model training and inference on previously unseen data. SLEAP features an accessible graphical user interface, a standardized data model, a reproducible configuration system, over 30 model architectures, two approaches to part grouping and two approaches to identity tracking. We applied SLEAP to seven datasets across flies, bees, mice and gerbils to systematically evaluate each approach and architecture, and we compare it with other existing approaches. SLEAP achieves greater accuracy and speeds of more than 800 frames per second, with latencies of less than 3.5\,ms at full 1,024\,\texttimes\,1,024 image resolution. This makes SLEAP usable for real-time applications, which we demonstrate by controlling the behavior of one animal on the basis of the tracking and detection of social interactions with another animal.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Computational neuroscience,Machine learning,Software},
  file = {/Users/roaldarbol/Zotero/storage/2B6HFUAE/Pereira et al._2022_SLEAP A deep learning system for multi-animal pose tracking.pdf}
}

@misc{Saunders2022,
  title = {{{AUTOPILOT}}: {{Automating}} Experiments with Lots of {{Raspberry Pis}}},
  shorttitle = {{{AUTOPILOT}}},
  author = {Saunders, Jonny L. and Ott, Lucas A. and Wehr, Michael},
  year = 2022,
  month = jun,
  publisher = {bioRxiv},
  doi = {10.1101/807693},
  urldate = {2025-02-23},
  abstract = {Neuroscience needs behavior, and behavioral experiments require the coordination of large numbers of heterogeneous hardware components and data streams. Currently available tools strongly limit the complexity and reproducibility of experiments. Here we introduce Autopilot, a complete, open-source Python framework for experimental automation that distributes experiments over networked swarms of Raspberry Pis. Autopilot enables qualitatively greater experimental flexibility by allowing arbitrary numbers of hardware components to be combined in arbitrary experimental designs. Research is made reproducible by documenting all data and task design parameters in a human-readable and publishable format at the time of collection. Autopilot provides a high-level set of programming tools while maintaining submillisecond performance at a fraction of the cost of traditional tools. Taking seriously the social nature of code, we scaffold shared knowledge and practice with a publicly editable semantic wiki and a permissive plugin system. Autopilot's flexible, scalable architecture allows neuroscientists to work together to design the next generation of experiments to investigate the behaving brain.},
  archiveprefix = {bioRxiv},
  copyright = {\copyright{} 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
  langid = {english},
  file = {/Users/roaldarbol/Zotero/storage/RV8RVFKP/Saunders et al._2022_AUTOPILOT Automating experiments with lots of Raspberry Pis.pdf}
}

@article{Schatz2022,
  title = {{{LabNet}} Hardware Control Software for the {{Raspberry Pi}}},
  author = {Schatz, Alexej and Winter, York},
  editor = {Mathis, Mackenzie W and Wassum, Kate M and Saunders, Jonny L and Lopes, Gon{\c c}alo},
  year = 2022,
  month = dec,
  journal = {eLife},
  volume = {11},
  pages = {e77973},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.77973},
  urldate = {2025-11-16},
  abstract = {Single-board computers such as the Raspberry Pi make it easy to control hardware setups for laboratory experiments. GPIOs and expansion boards (HATs) give access to a whole range of sensor and control hardware. However, controlling such hardware can be challenging, when many experimental setups run in parallel and the time component is critical. LabNet is a C++ optimized control layer software to give access to the Raspberry Pi connected hardware over a simple network protocol. LabNet was developed to be suitable for time-critical operations, and to be simple to expand. It leverages the actor model to simplify multithreading programming and to increase modularity. The message protocol is implemented in Protobuf and offers performance, small message size, and supports a large number of programming languages on the client side. It shows good performance compared to locally executed tools like Bpod, pyControl, or Autopilot and reaches sub-millisecond range in network communication latencies. LabNet can monitor and react simultaneously to up to 14 pairs of digital inputs, without increasing latencies. LabNet itself does not provide support for the design of experimental tasks. This is left to the client. LabNet can be used for general automation in experimental laboratories with its control PC located at some distance. LabNet is open source and under continuing development.},
  keywords = {behaviour,hardware,software},
  file = {/Users/roaldarbol/Zotero/storage/AEYUG7IS/Schatz and Winter_2022_LabNet hardware control software for the Raspberry Pi.pdf}
}

@article{Stih2019,
  title = {Stytra: {{An}} Open-Source, Integrated System for Stimulation, Tracking and Closed-Loop Behavioral Experiments},
  shorttitle = {Stytra},
  author = {{\v S}tih, Vilim and Petrucco, Luigi and Kist, Andreas M. and Portugues, Ruben},
  year = 2019,
  month = apr,
  journal = {PLOS Computational Biology},
  volume = {15},
  number = {4},
  pages = {e1006699},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1006699},
  urldate = {2025-11-16},
  abstract = {We present Stytra, a flexible, open-source software package, written in Python and designed to cover all the general requirements involved in larval zebrafish behavioral experiments. It provides timed stimulus presentation, interfacing with external devices and simultaneous real-time tracking of behavioral parameters such as position, orientation, tail and eye motion in both freely-swimming and head-restrained preparations. Stytra logs all recorded quantities, metadata, and code version in standardized formats to allow full provenance tracking, from data acquisition through analysis to publication. The package is modular and expandable for different experimental protocols and setups. Current releases can be found at https://github.com/portugueslab/stytra. We also provide complete documentation with examples for extending the package to new stimuli and hardware, as well as a schema and parts list for behavioral setups. We showcase Stytra by reproducing previously published behavioral protocols in both head-restrained and freely-swimming larvae. We also demonstrate the use of the software in the context of a calcium imaging experiment, where it interfaces with other acquisition devices. Our aims are to enable more laboratories to easily implement behavioral experiments, as well as to provide a platform for sharing stimulus protocols that permits easy reproduction of experiments and straightforward validation. Finally, we demonstrate how Stytra can serve as a platform to design behavioral experiments involving tracking or visual stimulation with other animals and provide an example integration with the DeepLabCut neural network-based tracking method.},
  langid = {english},
  keywords = {Behavior,Computer software,Fish,Larvae,Swimming,Tails,Vision,Zebrafish},
  file = {/Users/roaldarbol/Zotero/storage/KWVE8JSM/Štih et al._2019_Stytra An open-source, integrated system for stimulation, tracking and closed-loop behavioral exper.pdf}
}

@misc{zotero-6191,
  title = {{{MicroPython}} - a Lean and Efficient {{Python}} Implementation for Microcontrollers and Constrained Systems},
  author = {MicroPython},
  urldate = {2025-02-23},
  howpublished = {https://github.com/micropython/micropython},
  file = {/Users/roaldarbol/Zotero/storage/XXTYAPLH/micropython.html}
}

@misc{zotero-item-7401,
  title = {Bpod},
  author = {Sanders, J},
  year = 2021,
  howpublished = {Sanworks}
}
